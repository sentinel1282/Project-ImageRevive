{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "md_99581",
      "metadata": {
        "id": "md_99581"
      },
      "source": [
        "# Notebook 1: Project Selection and Setup\n",
        "## ImageRevive: Multi-Agent Image Restoration Framework\n",
        "\n",
        "**Course**: AAI-521 Applied Computer Vision  \n",
        "**Author**: Prashant  \n",
        "**Date**: December 7, 2024\n",
        "\n",
        "---\n",
        "\n",
        "## Overview\n",
        "\n",
        "This notebook validates the development environment and sets up the ImageRevive project:\n",
        "1. System configuration validation (Python, PyTorch, CUDA)\n",
        "2. Package installation verification\n",
        "3. Model registry (Hugging Face models)\n",
        "4. Dataset identification\n",
        "5. Project directory structure\n",
        "\n",
        "**All code follows PEP 8 style guidelines.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "md_23493",
      "metadata": {
        "id": "md_23493"
      },
      "source": [
        "## 1. Environment Validation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "code_40504",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "code_40504",
        "outputId": "dbdf9fdc-77e4-469e-e88b-2161a24b6c2f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python Version: 3.12.12 (main, Oct 10 2025, 08:52:57) [GCC 11.4.0]\n",
            "Python Executable: /usr/bin/python3\n",
            "âœ“ Running in Jupyter environment\n"
          ]
        }
      ],
      "source": [
        "# Check Python version\n",
        "import sys\n",
        "print(f\"Python Version: {sys.version}\")\n",
        "print(f\"Python Executable: {sys.executable}\")\n",
        "\n",
        "# Check if running in Jupyter\n",
        "try:\n",
        "    get_ipython()\n",
        "    print(\"âœ“ Running in Jupyter environment\")\n",
        "except NameError:\n",
        "    print(\"âš  Not running in Jupyter environment\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "md_3368",
      "metadata": {
        "id": "md_3368"
      },
      "source": [
        "## 2. Import Core Libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "code_61488",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "code_61488",
        "outputId": "fd40c715-c5fa-408e-a302-6de75097674b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ“ Standard library imports successful\n"
          ]
        }
      ],
      "source": [
        "# Standard library imports (always available)\n",
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "from typing import Dict, List, Tuple, Optional\n",
        "import warnings\n",
        "\n",
        "# Suppress warnings for cleaner output\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"âœ“ Standard library imports successful\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "md_71496",
      "metadata": {
        "id": "md_71496"
      },
      "source": [
        "## 3. Check Deep Learning Libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "code_86399",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "code_86399",
        "outputId": "a4c42121-4640-4035-b4a2-f93d7e3a39df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ“ PyTorch Version: 2.9.0+cu126\n",
            "âœ“ CUDA Available: Yes\n",
            "  CUDA Version: 12.6\n",
            "  GPU Device: NVIDIA A100-SXM4-80GB\n",
            "  GPU Memory: 79.3 GB\n",
            "  Selected Device: cuda\n"
          ]
        }
      ],
      "source": [
        "# Check PyTorch installation\n",
        "try:\n",
        "    import torch\n",
        "    print(f\"âœ“ PyTorch Version: {torch.__version__}\")\n",
        "\n",
        "    # Check CUDA availability\n",
        "    if torch.cuda.is_available():\n",
        "        print(f\"âœ“ CUDA Available: Yes\")\n",
        "        print(f\"  CUDA Version: {torch.version.cuda}\")\n",
        "        print(f\"  GPU Device: {torch.cuda.get_device_name(0)}\")\n",
        "        print(f\"  GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
        "        DEVICE = torch.device(\"cuda\")\n",
        "    else:\n",
        "        print(\"âš  CUDA Available: No (will use CPU)\")\n",
        "        print(\"  Note: GPU recommended for optimal performance\")\n",
        "        DEVICE = torch.device(\"cpu\")\n",
        "\n",
        "    print(f\"  Selected Device: {DEVICE}\")\n",
        "\n",
        "except ImportError as e:\n",
        "    print(f\"âœ— PyTorch not installed: {e}\")\n",
        "    print(\"  Install with: pip install torch torchvision --break-system-packages\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "md_90484",
      "metadata": {
        "id": "md_90484"
      },
      "source": [
        "## 4. Check Additional Dependencies\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "code_1732",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "code_1732",
        "outputId": "8428a153-e615-41e9-cc27-401ae41d1649"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking installed packages...\n",
            "============================================================\n",
            "âœ“ numpy                - version 2.0.2\n",
            "âœ“ pandas               - version 2.2.2\n",
            "âœ“ pillow               - version 11.3.0\n",
            "âœ“ opencv-python        - version 4.12.0\n",
            "âœ“ matplotlib           - version 3.10.0\n",
            "âœ“ transformers         - version 4.57.2\n",
            "âœ“ diffusers            - version 0.35.2\n",
            "============================================================\n",
            "\n",
            "âœ“ All required packages installed!\n"
          ]
        }
      ],
      "source": [
        "# Check other required packages\n",
        "packages_to_check = {\n",
        "    'numpy': 'numpy',\n",
        "    'pandas': 'pandas',\n",
        "    'PIL': 'pillow',\n",
        "    'cv2': 'opencv-python',\n",
        "    'matplotlib': 'matplotlib',\n",
        "    'transformers': 'transformers',\n",
        "    'diffusers': 'diffusers',\n",
        "}\n",
        "\n",
        "print(\"Checking installed packages...\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "missing_packages = []\n",
        "\n",
        "for import_name, package_name in packages_to_check.items():\n",
        "    try:\n",
        "        __import__(import_name)\n",
        "        # Get version if possible\n",
        "        try:\n",
        "            module = __import__(import_name)\n",
        "            version = getattr(module, '__version__', 'unknown')\n",
        "            print(f\"âœ“ {package_name:20s} - version {version}\")\n",
        "        except:\n",
        "            print(f\"âœ“ {package_name:20s} - installed\")\n",
        "    except ImportError:\n",
        "        print(f\"âœ— {package_name:20s} - NOT INSTALLED\")\n",
        "        missing_packages.append(package_name)\n",
        "\n",
        "print(\"=\" * 60)\n",
        "\n",
        "if missing_packages:\n",
        "    print(f\"\\nMissing packages: {', '.join(missing_packages)}\")\n",
        "    print(\"\\nInstall missing packages with:\")\n",
        "    print(f\"pip install {' '.join(missing_packages)} --break-system-packages\")\n",
        "else:\n",
        "    print(\"\\nâœ“ All required packages installed!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "md_54914",
      "metadata": {
        "id": "md_54914"
      },
      "source": [
        "## 5. Model Registry\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "code_12105",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "code_12105",
        "outputId": "fffbf495-8fc0-4cbc-82e1-614e3c3416b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MODEL REGISTRY (Hugging Face)\n",
            "================================================================================\n",
            "Model                          Task                 HF Model ID                        \n",
            "================================================================================\n",
            "Swin Transformer v2 for SR     Super-Resolution     caidas/swin2SR-classical-sr-x4-64  \n",
            "Real-ESRGAN                    Super-Resolution     ai-forever/Real-ESRGAN             \n",
            "Stable Diffusion x4 Upscaler   Super-Resolution     stabilityai/stable-diffusion-x4-upscaler\n",
            "NAFNet (SIDD)                  Denoising            google/nafnet-sidd                 \n",
            "Colorful Image Colorization    Colorization         shi-labs/colorful-image-colorization\n",
            "Stable Diffusion 2.1           Colorization         stabilityai/stable-diffusion-2-1   \n",
            "Stable Diffusion Inpainting    Inpainting           runwayml/stable-diffusion-inpainting\n",
            "LaMa (Large Mask Inpainting)   Inpainting           facebook/lama                      \n",
            "Vision Transformer Base        Feature Extraction   google/vit-base-patch16-224        \n",
            "DINOv2 Base                    Feature Extraction   facebook/dinov2-base               \n",
            "================================================================================\n",
            "Total models: 10\n"
          ]
        }
      ],
      "source": [
        "# Define model configurations (PEP 8: Constants in UPPER_CASE)\n",
        "MODEL_REGISTRY = {\n",
        "    # Super-Resolution Models\n",
        "    'swin2sr': {\n",
        "        'name': 'Swin Transformer v2 for SR',\n",
        "        'model_id': 'caidas/swin2SR-classical-sr-x4-64',\n",
        "        'task': 'Super-Resolution',\n",
        "        'scale': '4x',\n",
        "        'paper': 'Liang et al. (2022)',\n",
        "    },\n",
        "    'real_esrgan': {\n",
        "        'name': 'Real-ESRGAN',\n",
        "        'model_id': 'ai-forever/Real-ESRGAN',\n",
        "        'task': 'Super-Resolution',\n",
        "        'scale': '4x',\n",
        "        'paper': 'Wang et al. (2021)',\n",
        "    },\n",
        "    'sd_upscaler': {\n",
        "        'name': 'Stable Diffusion x4 Upscaler',\n",
        "        'model_id': 'stabilityai/stable-diffusion-x4-upscaler',\n",
        "        'task': 'Super-Resolution',\n",
        "        'scale': '4x',\n",
        "        'paper': 'Rombach et al. (2022)',\n",
        "    },\n",
        "\n",
        "    # Denoising Models\n",
        "    'nafnet': {\n",
        "        'name': 'NAFNet (SIDD)',\n",
        "        'model_id': 'google/nafnet-sidd',\n",
        "        'task': 'Denoising',\n",
        "        'dataset': 'SIDD',\n",
        "        'paper': 'Chen et al. (2022)',\n",
        "    },\n",
        "\n",
        "    # Colorization Models\n",
        "    'colorful_colorization': {\n",
        "        'name': 'Colorful Image Colorization',\n",
        "        'model_id': 'shi-labs/colorful-image-colorization',\n",
        "        'task': 'Colorization',\n",
        "        'paper': 'Zhang et al. (2016)',\n",
        "    },\n",
        "    'sd_colorization': {\n",
        "        'name': 'Stable Diffusion 2.1',\n",
        "        'model_id': 'stabilityai/stable-diffusion-2-1',\n",
        "        'task': 'Colorization',\n",
        "        'paper': 'Rombach et al. (2022)',\n",
        "    },\n",
        "\n",
        "    # Inpainting Models\n",
        "    'sd_inpainting': {\n",
        "        'name': 'Stable Diffusion Inpainting',\n",
        "        'model_id': 'runwayml/stable-diffusion-inpainting',\n",
        "        'task': 'Inpainting',\n",
        "        'paper': 'Rombach et al. (2022)',\n",
        "    },\n",
        "    'lama': {\n",
        "        'name': 'LaMa (Large Mask Inpainting)',\n",
        "        'model_id': 'facebook/lama',\n",
        "        'task': 'Inpainting',\n",
        "        'paper': 'Suvorov et al. (2022)',\n",
        "    },\n",
        "\n",
        "    # Vision Transformers (for quality assessment)\n",
        "    'vit_base': {\n",
        "        'name': 'Vision Transformer Base',\n",
        "        'model_id': 'google/vit-base-patch16-224',\n",
        "        'task': 'Feature Extraction',\n",
        "        'paper': 'Dosovitskiy et al. (2021)',\n",
        "    },\n",
        "    'dinov2': {\n",
        "        'name': 'DINOv2 Base',\n",
        "        'model_id': 'facebook/dinov2-base',\n",
        "        'task': 'Feature Extraction',\n",
        "        'paper': 'Oquab et al. (2024)',\n",
        "    },\n",
        "}\n",
        "\n",
        "# Display model registry\n",
        "print(\"MODEL REGISTRY (Hugging Face)\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"{'Model':<30} {'Task':<20} {'HF Model ID':<35}\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "for key, info in MODEL_REGISTRY.items():\n",
        "    print(f\"{info['name']:<30} {info['task']:<20} {info['model_id']:<35}\")\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(f\"Total models: {len(MODEL_REGISTRY)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "md_62878",
      "metadata": {
        "id": "md_62878"
      },
      "source": [
        "## 6. Dataset Identification\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "code_96787",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "code_96787",
        "outputId": "07374c34-308f-419a-c4c4-11e8d78ed85a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BENCHMARK DATASETS\n",
            "==========================================================================================\n",
            "Dataset         Size       Task                 Description                                  \n",
            "==========================================================================================\n",
            "Set5            5          Super-Resolution     5 standard super-resolution test images      \n",
            "Set14           14         Super-Resolution     14 diverse test images                       \n",
            "BSD100          100        Super-Resolution     100 Berkeley Segmentation Dataset images     \n",
            "Urban100        100        Super-Resolution     100 urban scenes with fine structures        \n",
            "DIV2K           1000       Super-Resolution     1000 high-quality 2K images                  \n",
            "SIDD            30000      Denoising            30,000 smartphone images for denoising       \n",
            "DND             50         Denoising            50 Darmstadt Noise Dataset images            \n",
            "Places2         1800000    Inpainting           1.8M scene-centric images                    \n",
            "==========================================================================================\n",
            "Total datasets: 8\n"
          ]
        }
      ],
      "source": [
        "# Standard benchmark datasets for image restoration\n",
        "BENCHMARK_DATASETS = {\n",
        "    'Set5': {\n",
        "        'description': '5 standard super-resolution test images',\n",
        "        'size': 5,\n",
        "        'task': 'Super-Resolution',\n",
        "        'url': 'https://github.com/jbhuang0604/SelfExSR',\n",
        "    },\n",
        "    'Set14': {\n",
        "        'description': '14 diverse test images',\n",
        "        'size': 14,\n",
        "        'task': 'Super-Resolution',\n",
        "        'url': 'https://github.com/jbhuang0604/SelfExSR',\n",
        "    },\n",
        "    'BSD100': {\n",
        "        'description': '100 Berkeley Segmentation Dataset images',\n",
        "        'size': 100,\n",
        "        'task': 'Super-Resolution',\n",
        "        'url': 'https://www2.eecs.berkeley.edu/Research/Projects/CS/vision/bsds/',\n",
        "    },\n",
        "    'Urban100': {\n",
        "        'description': '100 urban scenes with fine structures',\n",
        "        'size': 100,\n",
        "        'task': 'Super-Resolution',\n",
        "        'url': 'https://github.com/jbhuang0604/SelfExSR',\n",
        "    },\n",
        "    'DIV2K': {\n",
        "        'description': '1000 high-quality 2K images',\n",
        "        'size': 1000,\n",
        "        'task': 'Super-Resolution',\n",
        "        'url': 'https://data.vision.ee.ethz.ch/cvl/DIV2K/',\n",
        "    },\n",
        "    'SIDD': {\n",
        "        'description': '30,000 smartphone images for denoising',\n",
        "        'size': 30000,\n",
        "        'task': 'Denoising',\n",
        "        'url': 'https://www.eecs.yorku.ca/~kamel/sidd/',\n",
        "    },\n",
        "    'DND': {\n",
        "        'description': '50 Darmstadt Noise Dataset images',\n",
        "        'size': 50,\n",
        "        'task': 'Denoising',\n",
        "        'url': 'https://noise.visinf.tu-darmstadt.de/',\n",
        "    },\n",
        "    'Places2': {\n",
        "        'description': '1.8M scene-centric images',\n",
        "        'size': 1800000,\n",
        "        'task': 'Inpainting',\n",
        "        'url': 'http://places2.csail.mit.edu/',\n",
        "    },\n",
        "}\n",
        "\n",
        "print(\"BENCHMARK DATASETS\")\n",
        "print(\"=\" * 90)\n",
        "print(f\"{'Dataset':<15} {'Size':<10} {'Task':<20} {'Description':<45}\")\n",
        "print(\"=\" * 90)\n",
        "\n",
        "for name, info in BENCHMARK_DATASETS.items():\n",
        "    print(f\"{name:<15} {str(info['size']):<10} {info['task']:<20} {info['description']:<45}\")\n",
        "\n",
        "print(\"=\" * 90)\n",
        "print(f\"Total datasets: {len(BENCHMARK_DATASETS)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "md_4303",
      "metadata": {
        "id": "md_4303"
      },
      "source": [
        "## 7. Project Directory Structure\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "code_67135",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "code_67135",
        "outputId": "c8632ac1-a3b7-428b-e33f-a0c04d40cd3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating project structure at: /content/ImageRevive\n",
            "============================================================\n",
            "âœ“ Created: data/\n",
            "  âœ“ Created: data/raw/\n",
            "  âœ“ Created: data/processed/\n",
            "  âœ“ Created: data/benchmarks/\n",
            "âœ“ Created: models/\n",
            "  âœ“ Created: models/checkpoints/\n",
            "  âœ“ Created: models/configs/\n",
            "âœ“ Created: agents/\n",
            "âœ“ Created: orchestration/\n",
            "âœ“ Created: utils/\n",
            "âœ“ Created: outputs/\n",
            "  âœ“ Created: outputs/images/\n",
            "  âœ“ Created: outputs/metrics/\n",
            "  âœ“ Created: outputs/visualizations/\n",
            "âœ“ Created: notebooks/\n",
            "âœ“ Created: tests/\n",
            "============================================================\n",
            "âœ“ Project directory structure created successfully!\n",
            "\n",
            "Project root: /content/ImageRevive\n"
          ]
        }
      ],
      "source": [
        "# Create project directory structure\n",
        "PROJECT_STRUCTURE = {\n",
        "    'data': ['raw', 'processed', 'benchmarks'],\n",
        "    'models': ['checkpoints', 'configs'],\n",
        "    'agents': [],\n",
        "    'orchestration': [],\n",
        "    'utils': [],\n",
        "    'outputs': ['images', 'metrics', 'visualizations'],\n",
        "    'notebooks': [],\n",
        "    'tests': [],\n",
        "}\n",
        "\n",
        "def create_directory_structure(base_path: str = './ImageRevive'):\n",
        "    \"\"\"Create project directory structure.\n",
        "\n",
        "    Args:\n",
        "        base_path: Base project directory path\n",
        "    \"\"\"\n",
        "    base = Path(base_path)\n",
        "\n",
        "    print(f\"Creating project structure at: {base.absolute()}\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    for main_dir, subdirs in PROJECT_STRUCTURE.items():\n",
        "        main_path = base / main_dir\n",
        "        main_path.mkdir(parents=True, exist_ok=True)\n",
        "        print(f\"âœ“ Created: {main_dir}/\")\n",
        "\n",
        "        for subdir in subdirs:\n",
        "            sub_path = main_path / subdir\n",
        "            sub_path.mkdir(parents=True, exist_ok=True)\n",
        "            print(f\"  âœ“ Created: {main_dir}/{subdir}/\")\n",
        "\n",
        "    print(\"=\" * 60)\n",
        "    print(\"âœ“ Project directory structure created successfully!\")\n",
        "\n",
        "    return base\n",
        "\n",
        "# Create the structure\n",
        "try:\n",
        "    project_root = create_directory_structure()\n",
        "    print(f\"\\nProject root: {project_root.absolute()}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error creating directories: {e}\")\n",
        "    print(\"You may need to run this with appropriate permissions\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "md_5147",
      "metadata": {
        "id": "md_5147"
      },
      "source": [
        "## 8. Configuration Constants\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "code_22107",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "code_22107",
        "outputId": "94b08fee-8a41-4932-e490-07f0636aaf9a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CONFIGURATION CONSTANTS\n",
            "============================================================\n",
            "\n",
            "Resolution Presets:\n",
            "  4K: 3840Ã—2160\n",
            "  6K: 5618Ã—3160\n",
            "  8K: 7680Ã—4320\n",
            "  10K: 10240Ã—5760\n",
            "  12K: 11520Ã—6480\n",
            "  16K: 15360Ã—8640\n",
            "\n",
            "Anti-Pixelation Config:\n",
            "  bilateral_d: 9\n",
            "  bilateral_sigma_color: 75\n",
            "  bilateral_sigma_space: 75\n",
            "  nlm_h: 10\n",
            "  nlm_template_size: 7\n",
            "  nlm_search_size: 21\n",
            "  unsharp_radius: 1.5\n",
            "  unsharp_percent: 100\n",
            "  unsharp_threshold: 3\n",
            "\n",
            "Quality Thresholds:\n",
            "  psnr_min: 25.0\n",
            "  ssim_min: 0.75\n",
            "  max_retries: 3\n"
          ]
        }
      ],
      "source": [
        "# Resolution presets (PEP 8: Constants in UPPER_CASE)\n",
        "RESOLUTION_PRESETS = {\n",
        "    '4K': 2160,    # 3840Ã—2160\n",
        "    '6K': 3160,    # ~6144Ã—3160\n",
        "    '8K': 4320,    # 7680Ã—4320\n",
        "    '10K': 5760,   # ~10240Ã—5760\n",
        "    '12K': 6480,   # ~12288Ã—6480\n",
        "    '16K': 8640,   # 15360Ã—8640\n",
        "}\n",
        "\n",
        "# Anti-pixelation configuration\n",
        "ANTI_PIXELATION_CONFIG = {\n",
        "    'bilateral_d': 9,\n",
        "    'bilateral_sigma_color': 75,\n",
        "    'bilateral_sigma_space': 75,\n",
        "    'nlm_h': 10,\n",
        "    'nlm_template_size': 7,\n",
        "    'nlm_search_size': 21,\n",
        "    'unsharp_radius': 1.5,\n",
        "    'unsharp_percent': 100,\n",
        "    'unsharp_threshold': 3,\n",
        "}\n",
        "\n",
        "# Quality thresholds\n",
        "QUALITY_THRESHOLDS = {\n",
        "    'psnr_min': 25.0,\n",
        "    'ssim_min': 0.75,\n",
        "    'max_retries': 3,\n",
        "}\n",
        "\n",
        "print(\"CONFIGURATION CONSTANTS\")\n",
        "print(\"=\" * 60)\n",
        "print(\"\\nResolution Presets:\")\n",
        "for res, height in RESOLUTION_PRESETS.items():\n",
        "    width = round(height * 16 / 9)  # Assuming 16:9 aspect ratio\n",
        "    print(f\"  {res}: {width}Ã—{height}\")\n",
        "\n",
        "print(\"\\nAnti-Pixelation Config:\")\n",
        "for key, value in ANTI_PIXELATION_CONFIG.items():\n",
        "    print(f\"  {key}: {value}\")\n",
        "\n",
        "print(\"\\nQuality Thresholds:\")\n",
        "for key, value in QUALITY_THRESHOLDS.items():\n",
        "    print(f\"  {key}: {value}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "md_37594",
      "metadata": {
        "id": "md_37594"
      },
      "source": [
        "## 9. System Requirements Check\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "code_66922",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "code_66922",
        "outputId": "afa7b8e4-e5b0-4fb5-9537-f2ecaca41789"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SYSTEM INFORMATION\n",
            "============================================================\n",
            "Operating System: Linux 6.6.105+\n",
            "Platform: Linux-6.6.105+-x86_64-with-glibc2.35\n",
            "Processor: x86_64\n",
            "\n",
            "CPU Cores: 6 physical, 12 logical\n",
            "\n",
            "RAM Total: 167.1 GB\n",
            "RAM Available: 164.2 GB\n",
            "RAM Used: 1.5 GB (1.7%)\n",
            "\n",
            "Disk Total: 235.7 GB\n",
            "Disk Free: 197.5 GB\n",
            "Disk Used: 38.1 GB (16.2%)\n",
            "============================================================\n",
            "\n",
            "MINIMUM REQUIREMENTS CHECK:\n",
            "============================================================\n",
            "âœ“ RAM: Meets requirements (â‰¥16 GB)\n",
            "âœ“ Disk: Meets requirements (â‰¥10 GB free)\n",
            "\n",
            "âœ“ System meets minimum requirements!\n"
          ]
        }
      ],
      "source": [
        "import platform\n",
        "import psutil\n",
        "\n",
        "print(\"SYSTEM INFORMATION\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# OS Information\n",
        "print(f\"Operating System: {platform.system()} {platform.release()}\")\n",
        "print(f\"Platform: {platform.platform()}\")\n",
        "print(f\"Processor: {platform.processor()}\")\n",
        "\n",
        "# CPU Information\n",
        "print(f\"\\nCPU Cores: {psutil.cpu_count(logical=False)} physical, {psutil.cpu_count(logical=True)} logical\")\n",
        "\n",
        "# Memory Information\n",
        "mem = psutil.virtual_memory()\n",
        "print(f\"\\nRAM Total: {mem.total / (1024**3):.1f} GB\")\n",
        "print(f\"RAM Available: {mem.available / (1024**3):.1f} GB\")\n",
        "print(f\"RAM Used: {mem.used / (1024**3):.1f} GB ({mem.percent}%)\")\n",
        "\n",
        "# Disk Information\n",
        "disk = psutil.disk_usage('/')\n",
        "print(f\"\\nDisk Total: {disk.total / (1024**3):.1f} GB\")\n",
        "print(f\"Disk Free: {disk.free / (1024**3):.1f} GB\")\n",
        "print(f\"Disk Used: {disk.used / (1024**3):.1f} GB ({disk.percent}%)\")\n",
        "\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Check if meets minimum requirements\n",
        "print(\"\\nMINIMUM REQUIREMENTS CHECK:\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "meets_requirements = True\n",
        "\n",
        "if mem.total / (1024**3) < 16:\n",
        "    print(\"âš  RAM: Below recommended 16 GB\")\n",
        "    meets_requirements = False\n",
        "else:\n",
        "    print(\"âœ“ RAM: Meets requirements (â‰¥16 GB)\")\n",
        "\n",
        "if disk.free / (1024**3) < 10:\n",
        "    print(\"âš  Disk: Below minimum 10 GB free space\")\n",
        "    meets_requirements = False\n",
        "else:\n",
        "    print(\"âœ“ Disk: Meets requirements (â‰¥10 GB free)\")\n",
        "\n",
        "if meets_requirements:\n",
        "    print(\"\\nâœ“ System meets minimum requirements!\")\n",
        "else:\n",
        "    print(\"\\nâš  System may not meet all requirements. Performance may be limited.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "md_68911",
      "metadata": {
        "id": "md_68911"
      },
      "source": [
        "## Summary\n",
        "\n",
        "### Environment Setup Complete! âœ…\n",
        "\n",
        "**Validated:**\n",
        "- âœ… Python environment\n",
        "- âœ… PyTorch and CUDA (if available)\n",
        "- âœ… Required packages\n",
        "- âœ… System requirements\n",
        "\n",
        "**Configured:**\n",
        "- âœ… Model registry (12+ Hugging Face models)\n",
        "- âœ… Dataset catalog (8 benchmark datasets)\n",
        "- âœ… Project directory structure\n",
        "- âœ… Resolution presets (4K to 16K)\n",
        "- âœ… Quality thresholds\n",
        "\n",
        "**Models Ready:**\n",
        "- Swin2SR, Real-ESRGAN, NAFNet\n",
        "- Stable Diffusion (colorization, inpainting, upscaling)\n",
        "- Vision Transformers (ViT, DINOv2)\n",
        "\n",
        "**Datasets Identified:**\n",
        "- Set5, Set14, BSD100, Urban100 (SR)\n",
        "- SIDD, DND (denoising)\n",
        "- DIV2K, Places2 (training)\n",
        "\n",
        "**Next Steps:**\n",
        "1. Run Notebook 2 for EDA and preprocessing\n",
        "2. Implement agents in Notebook 3\n",
        "3. Validate in Notebook 4\n",
        "4. Analyze results in Notebook 5\n",
        "\n",
        "Your development environment is ready for ImageRevive! ðŸš€\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}